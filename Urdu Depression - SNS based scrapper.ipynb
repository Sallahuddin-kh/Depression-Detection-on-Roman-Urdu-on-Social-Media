{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75272ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works only on python 3.8+\n",
    "#For installation >pip3 install snscrape\n",
    "#Official Repo https://github.com/JustAnotherArchivist/snscrape\n",
    "#Tutorial https://medium.com/dataseries/how-to-scrape-millions-of-tweets-using-snscrape-195ee3594721\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6838164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making file for \"depression hai\" 1-1000\n",
      "Making file for \"depression hai\" 1000-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53973/3206914407.py:34: FutureWarning: content is deprecated, use rawContent instead\n",
      "  tweets_list.append([search_string, tweet.date, tweet.id, tweet.content, tweet.user.username])\n"
     ]
    }
   ],
   "source": [
    "tweets_list = []\n",
    "step = 1000\n",
    "start_limit = 1\n",
    "end_limit = 1000\n",
    "# string_list = ['ڈپریشن کا شکار ہوں',\n",
    "#                'ڈپریشن کا مریض ہوں',\n",
    "#                'ڈپریشن ہے',\n",
    "#                'ڈپریشن میں مبتلا ہوں',\n",
    "#                'ذہنی دباؤ ہے',\n",
    "#                'شدید ڈپریشن کا شکار',\n",
    "#                'مجھے خود سے نفرت ہے',\n",
    "#                'میں خود سے نفرت کرتا ہوں',\n",
    "#                'میں خود کشی کرنا چاہتا ہوں',\n",
    "#                'میں خود کو مارنے جا رہا ہوں',\n",
    "#                'میں اب جینا نہیں چاہتا',\n",
    "#                'میں زندہ نہیں رہنا چاہتا',\n",
    "#                'میں زندگی سے مایوس ہو',\n",
    "#                'مجھے کچھ اچھا نہیں لگتا',\n",
    "#                'مجھے اظطراب بیماری ہے']\n",
    "\n",
    "string_list = ['depression hai',\n",
    "#               'depressed hoon',\n",
    "#               'depression ka',\n",
    "#               'main zinda nahin rehna chahta',\n",
    "#               'main suicide',\n",
    "#               'main marna',\n",
    "#               'khud se nafrat'\n",
    "              ]\n",
    "for string in string_list:\n",
    "    search_string = \"\\\"\"+string+\"\\\"\"\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_string).get_items()):\n",
    "        if tweet.quotedTweet != None or tweet.quotedTweet != None:\n",
    "            continue\n",
    "        tweets_list.append([search_string, tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "        if i%step == 0:\n",
    "            tweets_df = pd.DataFrame(tweets_list, columns=['search_string', 'date', 'tweet Id', 'text', 'username'])\n",
    "            tweets_df = tweets_df.drop_duplicates()\n",
    "            print(f'Making file for {search_string} {start_limit}-{end_limit}')\n",
    "            tweets_df.to_csv(f'{search_string} {start_limit}-{end_limit} sns.csv', sep=',', index=False) \n",
    "            start_limit = end_limit\n",
    "            end_limit += step\n",
    "            tweets_list = []\n",
    "            break\n",
    "    tweets_df = pd.DataFrame(tweets_list, columns=['search_string', 'date', 'tweet Id', 'text', 'username'])\n",
    "    tweets_df = tweets_df.drop_duplicates()\n",
    "    print(f'Making file for {search_string} {start_limit}-{end_limit}')\n",
    "    tweets_df.to_csv(f'{search_string} {start_limit}-{end_limit} roman-sns.csv', sep=',', index=False) \n",
    "    start_limit = end_limit\n",
    "    end_limit += step\n",
    "    tweets_list = [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe52d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sns-iter-original.csv', encoding = 'utf-8')\n",
    "le = df.shape[0]\n",
    "tweets_list2 = []\n",
    "for user in range(le):\n",
    "    d = df['date'][user]\n",
    "    d = d.split(' ')\n",
    "    date_format = '%Y-%m-%d'\n",
    "    dtObj = dt.datetime.strptime(d[0],date_format)\n",
    "    future_date = dtObj + relativedelta(days=3)\n",
    "    past_date = dtObj - relativedelta(days=3)\n",
    "    future_date = future_date.strftime(date_format)\n",
    "    past_date = past_date.strftime(date_format)\n",
    "    search_string = f\"from:{df['username'][user]} since:{past_date} until:{future_date} lang:ur\"\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_string).get_items()):\n",
    "        tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bf02095",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "tweets_df2 = tweets_df2.drop_duplicates()\n",
    "tweets_df2.to_csv('sns-iter-1.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584b5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
